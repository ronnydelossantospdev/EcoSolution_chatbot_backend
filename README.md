
# ğŸŒ± EcoSolution_chatbot_backend â€“ API de Entrenamiento y Consumo de Modelo ML

<br>

## Indice

- [ğŸ“Œ DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)

    - [ğŸ§  Â¿CÃ³mo funciona el sistema?](#-cÃ³mo-funciona-el-sistema)

    - [ğŸ“Š Dataset utilizado?](#-dataset-utilizado)

    - [#ğŸ¤– Modelo de Machine Learning](#-modelo-de-machine-learning)

    - [ğŸ“¦ Archivos generados durante el entrenamiento](#-archivos-generados-durante-el-entrenamiento)

    - [âš¡ Entrenamiento](#-entrenamiento)

    - [ğŸŒ API del Proyecto](#-api-del-proyecto)

    - [ğŸ“š DocumentaciÃ³n de Endpoints](#-documentaciÃ³n-de-endpoints)

        - [âœ… Endpoint de Bienvenida](#-endpoint-de-bienvenida)

        - [âœ… Endpoint para Consultas](#-endpoint-para-consultas)



- [ConfiguraciÃ³n y ejecuciÃ³n del proyecto](#configuraciÃ³n-y-ejecuciÃ³n-del-proyecto)

    - [âœ… 1. Crear entorno virtual](#-1-crear-entorno-virtual)
    
    - [âœ… 2. Activar entorno virtual](#-2-activar-entorno-virtual)

    - [âœ… 3. Instalar dependencias](#-3-instalar-dependencias)

    - [âœ… 4. Ejecutar el proyecto](#-4-ejecutar-el-proyecto)

    - [ğŸ›‘ 5. Detener el proyecto](#-5-detener-el-proyecto)

    - [ğŸ”’ 6. Salir del entorno virtual](#-6-salir-del-entorno-virtual)



<br><br>

# ğŸ“Œ DescripciÃ³n del Proyecto

El **EcoSolution_chatbot_backend** es una API desarrollada en **Python** cuyo objetivo principal es entrenar y ejecutar un modelo de Machine Learning.

Este sistema permite:

- Entrenar un modelo de clasificaciÃ³n de texto
- Generar archivos de modelo entrenado
- Consumir el modelo mediante una API REST
- Procesar preguntas y generar respuestas automÃ¡ticas

<br>

---

### ğŸ§  Â¿CÃ³mo funciona el sistema?

El proyecto utiliza tÃ©cnicas de **Procesamiento de Lenguaje Natural (NLP)** y **Machine Learning** para interpretar preguntas escritas por el usuario y generar respuestas automÃ¡ticas.

El flujo general es:

1. Se recibe un dataset con preguntas y respuestas.
2. El sistema entrena un modelo usando regresiÃ³n logÃ­stica.
3. Se genera un modelo entrenado.
4. La API utiliza ese modelo para responder preguntas.

<br>

---

### ğŸ“Š Dataset utilizado

El modelo se entrena utilizando el siguiente archivo:

```bash
dataset/medio_ambiente_dataset.csv
```

Este dataset contiene informaciÃ³n relacionada con temas medioambientales, que sirve como base para que el modelo aprenda patrones y respuestas.

<br>

---

### ğŸ¤– Modelo de Machine Learning

El modelo fue construido utilizando:

- Algoritmo: RegresiÃ³n LogÃ­stica
- VectorizaciÃ³n: TF-IDF (Term Frequency - Inverse Document Frequency)

<br>

ğŸ”¹ **RegresiÃ³n LogÃ­stica**

Es un algoritmo de Machine Learning que aprende patrones matemÃ¡ticos y estadÃ­sticos a partir de datos para clasificar texto.

ğŸ”¹ **TF-IDF**

Se utiliza para convertir texto en valores numÃ©ricos que el modelo puede interpretar.


<br>

---

### ğŸ“¦ Archivos generados durante el entrenamiento

Cuando el modelo es entrenado, se generan los siguientes archivos:

| **Archivo** |	**DescripciÃ³n** |
|--|--|
| `modelo.pkl`  |	Contiene el modelo entrenado |
| `vectorizer_tfidf.pkl`	| Convierte texto en datos numÃ©ricos

<br>

---

### âš¡ Entrenamiento

El proyecto incluye un scripts para entrenar el modelo.

```bash
algoritmo_modelo.py
```
<br>

---

### ğŸŒ API del Proyecto

El archivo principal de la API es:

```bash
api.py
```

Esta API permite consumir el modelo previamente entrenado.


<br>

---

### ğŸ“š DocumentaciÃ³n de Endpoints

---

### âœ… Endpoint de Bienvenida

GET /
ğŸ”¹ **DescripciÃ³n**

Retorna un mensaje inicial del sistema.

ğŸ”¹ **Response**
```json
{
    "mensaje": [
        "Â¡Hola!",
        "Â¿CÃ³mo puedo ayudarte?"
    ]
}
```

---

### âœ… Endpoint para Consultas

POST /datos

ğŸ”¹ **DescripciÃ³n**

Recibe una pregunta del usuario, la procesa mediante el modelo entrenado y retorna una respuesta.


ğŸ”¹ **Payload**
```json
{
    "pregunta": "hola"
}
```

ğŸ”¹ **Response**
```json
{
    "mensaje": "muy bien espero que tÃº tambiÃ©n te encuentres bien"
}
```

<br><br><br><br><br>

# ğŸš€ConfiguraciÃ³n y ejecuciÃ³n del proyecto
<br>

Este documento explica cÃ³mo configurar y ejecutar el proyecto paso a paso.

## âœ… 1. Crear entorno virtual

El entorno virtual permite instalar dependencias solo para este proyecto.

Ejecutar en la raÃ­z del proyecto:
```bash
python -m venv venv
```
<br>

## âœ… 2. Activar entorno virtual
ğŸ”¹ **En Windows (PowerShell)**

```bash
.\venv\Scripts\activate
```

Si se activÃ³ correctamente, verÃ¡s algo asÃ­:

```bash
(venv) PS C:\ruta\proyecto>
```
<br>

## âœ… 3. Instalar dependencias

Instalar todas las librerÃ­as necesarias usando el archivo requirements.txt.

```bash
pip install -r requirements.txt
```

<br>

## âœ… 4. Ejecutar el proyecto
```bash
python api_flask.py
```

El servidor Flask iniciarÃ¡ en modo desarrollo.

<br>

## ğŸ›‘ 5. Detener el proyecto

Para detener el servidor Flask:
```bash
Ctrl + C
```
<br>

## ğŸ”’ 6. Salir del entorno virtual

Cuando termines de trabajar:

```bash
deactivate
```